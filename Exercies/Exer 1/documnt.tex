\documentclass{article}

\usepackage{listings}
\usepackage{xcolor}

\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}

\usepackage{diagbox }

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}

\lstdefinestyle{customc}{
    language={[5.0]Lua},
    frame=L,
    xleftmargin=\parindent,
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    captionpos=b,                    
    keepspaces=true,                                  
    showspaces=true,                
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{escapechar=@,style=customc}

\usepackage{fancyhdr}
\pagestyle{fancy}

\fancyhead[R]{
تمرین سری اول هوش مصنوعی
}

\usepackage{xepersian}
\settextfont{XB Niloofar}

\begin{document}
\section*{سوال اول}
از آنجایی که نمی‌توان در زمان برنامه‌ سازی برای مدلی تمام حالات برای محیط و خود عامل را در نظر گرفت، بنابرین لازم است بخشی از رفتار‌ها بر اساس دانش باشد، به طوری که عامل بر اساس رفتار ها و تحلیل اتفاق‌ها و دنباله ادراک با کشف الگو‌ها و حقایق، در مراحل بعدی عمل کند. برای مثال انسان‌ها در کودکی توانایی درک زبان اطرافیان را ندارد، بنابرین مغز انسان در کودکی توانایی تحلیل و درک آنها را ندارد، در حالی که با گذشت زمان و با توجه به دنباله اتفاقات و کشف الگوها می‌تواند آن‌ را درک کند. این درک یا الگو و حقیقت کشف شده از محیط را ‌می‌توان دانش نامید، و برای به دست آوردن آن می‌توان روابط محیط را با استفاده از تحلیل خروجی حسگر‌ها به دست آورد و حتی می‌توان ‌با بررسی تاثیر رفتار از طریق عمگرها بر روی محیط و تحلیل آنها دانش به دست آورد.

از طرف دیگر عاملی که از محیط بیرون دانش به دست نمی‌‌آورد عملا از محیط مستقل عمل می‌کند و با محیط انطباقی نخواهد داشت، به عبارت دیگر یکی از ویژگی‌های هوشمند بودن را ندارد.

\section*{سوال دوم}
عامل به صورت واکنشی ساده یا 
\lr{Simple Reflex}
 عمل می‌کند، زیرا بدون در نظر گرفتن دنبال ادراک یا نگه داشتن حالت ذهنی قبلی، فقط براساس مشاهده فعلی از محیط، عمل مناسب را انجام می‌دهد. و البته اینکه می‌توان روند تصمیم‌گیری عامل را به صورت چند موقعیت شرطی توصیف کرد.

\begin{latin}
\begin{lstlisting}
function reflex-agent (temperature)
	if(temperature < LOWER_THRESOLD - 3)
	then 
		return 'TRUN_ON'
	elseif(temperature < UPPER_THRESHOLD + 3) 
	then 
		return 'TURN_OFF'
	else
		return 'DO NOTHING'
	end
end
\end{lstlisting}
\end{latin}

\section*{سوال سوم}

\subsection*{الف)}
\begin{itemize}
	\item کارایی:
		کم کردن ترافیک خیابان‌ها به عنوان هدف اصلی، مجموع وضعیت ماشین‌ها(به گونه‌ای که بخاطر کم شدن ترافیک میسر حرکت زیاد پیچیده یا طولانی نشود)  که می‌توان وضعیت کلی سادگی و سرعت ماشین‌ها در نظر گرفت.
	\item محیط:
	خیابان‌ها، ماشین‌ها، بقیه‌ ماشین‌های گروه تحت کنترل، عابرین	

	\item عمگرها:
وسایل‌ کنترل کننده برای تک تک ماشین‌ها(ترمز، گاز و راهنما و...)، وسایل ارتباطی با بقیه ماشین‌های گروه یا مرکز کنترل کننده.	

	\item سنسورها: 
وسایل تشیخص وضعیت برای تک تک ماشین‌ها(دوربین، سنسور صدا، GPS، حسگر‌های خودرو)، ورودی‌های ارتباطی با بقیه ماشین‌ها و مرکز کنترل کننده.
\end{itemize}


\subsection*{ب)}
\begin{itemize}
	\item کارایی:
مدت زمان خرید، قیمت نهایی، کیفیت بعضی از محصولات مثل سبزیجات نیز می‌تواند ملاک کارایی باشد.

	\item محیط:
خیابان‌ها، مغازه‌ و فروشگاه‌ها، فروشندگان، بقیه خریداران

	\item عمگرها:
عملگر‌های حرکتی(چرخ برای حرکت و بازو برای جابجایی لوازم) ، ابزار‌های برقراری ارتباط صوتی

	\item سنسورها: 
سنسور بینایی برای تشخصی جهت و اجناس، سنسور شنوایی برای برقراری ارتباطات، سنسور های اضافی برای تشخیص کیفیت کالاها، جی پی اس و ابزار‌های مکان‌یابی
\end{itemize}


\subsection*{پ)}
\begin{itemize}
	\item کارایی:
میزان خطا‌ها در زمینه‌های مختلف، میانگین عملکرد دانشجویان(برای مثال میانگین نمرات)، مجموع هزینه‌ها، بازخورد عوامل دانشگاه

	\item محیط:
محوطه دانشگاه، اساتید و دانشجویان، خدمه و کارکنان، کلاس‌ها، سالن‌ها، محل ذخیره‌سازی اطلاعات اعضا

	\item عمگرها:
عملگر‌های ارتباط صوتی، عملگرهای حرکتی، ابزارهایی برای استفاده از سیستم‌های اطلاعاتی دانشگاه

	\item سنسورها: 
سنسور بینایی و شنوایی، منابع اطلاعاتی و دیتابیس‌ها
\end{itemize}

\begin{itemize}
\subsubsection*{در صورتی که به صورت نرم افزاری پیاده خواهد شد}

\item عمگرها:
صفحه نمایش، تغییر دهنده اطلاعات مربوط به منابع اطلاعاتی، بقیه عملگر‌های دانشگاه

\item سنسورها: 
دیتابیس‌ها، ورودی‌های کامپیوتر مثل صفحه کلید، بقیه سنسورهای دانشگاه
\end{itemize}


\subsection*{ت)}
\begin{itemize}
	\item کارایی:
میزان خطا در انتخاب(کیفیت نهایی محصولات چیده شده)، سرعت تشخیص محصولات باکیفیت

	\item محیط:
محیط گلخانه، تمام گیاهان

	\item عمگرها:
عوامل حرکتی، بازوها برای چیدن محصولات

	\item سنسورها: 
سنسورهای بینایی، سنسورهایی برای انجام و گرفتن نتیجه تست‌های شیمیایی

\end{itemize}

\section*{سوال چهارم}
\begin{itemize}
	\item معیار کارایی:
		براساس نقش عامل میتوان عامل‌های مختلف با ضریب اهمیت مختلف داشت. برای مثلا تعداد گل‌ها، دفاع‌ها، پاس‌های موفق و ناموفق، حتی میزان جابجایی توپ و ...

	\item محیط:
	محوطه بازی، دیگر بازیکن‌ها، توپ، مربی‌ها، داورها

	\item عملگر‌ها:
	عملگر‌هایی برای حرکت و ضربه زدن به توپ و دیگر بازیکن ها، ابزار‌های ارتباطی با دیگر بازیکنان، داورها و مربی‌ها(که بستگی به پیاده سازی بقیه دارد) برای مثال می‌تواند از نوع گفتار، یا ارتباط از راه دور باشد.

	\item سنسورها: 
	سنسور‌های بینایی، سنسورهایی برای دریافت اطلاعات از بقیه‌ بازیکنان، داور‌ها و مربی‌ها( مثلا شنوایی)، ابزارهایی برای دریافت اطلاعات اصلی بازی مثل تعداد گل‌ها و زمان باقی‌مانده.
	\item خواص محیط:
محیط به صورت کامل رویت پذیر، استراتژیک، ترتیبی، پویا، پیوسته و از نظر تعداد عوامل چندعاملی است.
\end{itemize}
\section*{سوال پنجم}
\begin{itemize}
	\item معیار کارایی:
تعداد تصادفات به عنوان یک معیار مهم، میزان ترافیک ایجاد شده و همچنین از معیار‌های پیچیده‌ای مثل مجموع زمان انتظار ماشین‌ها می‌توان استفاده کرد.

	\item محیط:
	تمام چراغ‌های راهنما، ماشین‌ها، عابرین پیاده و گیرنده‌های دیگر مثل سرعت سنج‌ها و ترافیک سنج‌ها.

	\item عملگر‌ها:
	چراغ‌های راهنما.

	\item سنسورها: 
	خروجی سرعت‌ سنج‌ها، وضعیت چراغ‌ها، همچنین سنسور بینایی.
\end{itemize}

به طور کلی به سادگی می‌توان دید که نمی‌توان براساس تنها موقعیت فعلی تصمیم گرفت که وضعیت چراغ چگونه خواهد بود. بنابرین مدل واکنشی ساده نمی‌تواند مسئله را به درستی حل کند. در حالی که سیستم کنترل ترافیک پیچیدگی زیادی ندارد و عملا سیستم نیازی به یادگیری موقعیت‌های جدید ندارد. بنابرین می‌توان عامل را به صورت
\lr{model-based}
طراحی کرد.

\section*{سوال ششم}
عامل هوشمند با استفاده از سنسور خود از می‌تواند فقط از وضعیت خانه‌‌ای که در آن قرار دارد اطلاع پیدا کند و برای خانه‌های دیگر مجبور به تلف کردن انرژی برای سر زدن به آنها خواهد بود. اما می‌توان عامل را از مدل واکنشی ساده پیچیده‌تر کرد و با استفاده طراحی 
\lr{model-based}
به صورتی وضعیت خانه کناری را بر اساس اخرین زمانی که پاکسازی شده است حدس زد. بدین صورت که با استفاده از نرخ آلودگی احتمال آلوده بودن آن‌ را به دست آورد و فقط در صورتی که از حد خاصی(برای مثال ۹۵ درصد) بالاتر است به آن خانه سر زد تا آلودگی بررسی و پاکسازی شود. بنابرین حالت جدیدی هم برای عکس العمل در نظر می‌گیریم برای مواقعی که خانه فعلی تمیز است و خانه کناری به تازگی پاکسازی شده و نیازی به بررسی ندارد اضافه می‌شود. درین شرایط عامل کاری نباید انجام شود یا باید دستور حرکت به خانه فعلی داده شود.


برای پیاده سازی شبه‌ کد، متغیری به عنوان
\lr{state}
 به عنوان زمان گذشته از آخرین پاکسازی خانه کناری و در نظر می‌گیریم و بر اساس آن عمل می‌کنیم.
پس تابع 
\lr{update-state}
در صورتی که عامل در موقعیت کنونی خواهد ماند به
 \lr{state}
 یک واحد اضافه می‌کند تا در مراحل بعدی احتمال کثیف بودن خانه کناری را بالاتر در نظر بگیرد در غیر اینصورت  مقدار را به عنوان نمادی برای شروع حرکت به خانه بعدی $-1$ می‌گذارد
برای پیدا کردن احتمال کثیف شدن خانه کناری با استفاده از اخرین باری که بازدید شده از تابع زیر استفاده می‌کنیم.
\begin{latin}
\begin{lstlisting}
function OtherLocationStatus(fromLastTimeVisited)
	return 1 - (0.9) ^ fromLastTimeVisited
end
\end{lstlisting}
\end{latin}

منطق آپدیت حالت درونی عامل:
\begin{latin}
\begin{lstlisting}
function Update-state(state, action, [location, isDirty])
	-- if there isn't a strong likelyhood or current location is dirty for sure --
	if(OtherLocationStatus(state) > 0.95 or isDirty) 
	then
		state = state + 1 
	else 
		state = -1 	-- start moving to the other location --
	end
end
\end{lstlisting}
\end{latin}

بخاطر سادگی مدل از
 \lr{rule}
 صرف نظر می‌کنیم و به صورت مستقیم
 \lr{action}
را به عنوان خروجی در نظر میگیریم.
\begin{latin}
\begin{lstlisting}
function ActionMatch(state, [location, isDirty])
	if(isDirty)
	then
		if return SUCK
	elseif(state == -1)  -- moving to the next location --
	then
		if location == 'LEFT' return 'RIGHT' else return 'LEFT'
	else
		return 'NOTHING'
	end
end
\end{lstlisting}
\end{latin}

و تابع عکس العمل هم به صورت زیر تعریف می‌شود.
\begin{latin}
\begin{lstlisting}
function reflex-agent-with-state(percept)
	state = UpdateState(state, action, [percept])
	action = ActionMatch(state, percept)
	return action
end
\end{lstlisting}
\end{latin}

\section*{سوال هفتم}

\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|c|cccccc|}
\hline
\slashbox{خواص}{محیط کار}
 & رویت پذیری & قطعیت & مرحله‌ای بودن & ایستایی  & گسستگی & تعدد عوامل\\
\hline
حکم & جزئی & اتفاقی & ترتیبی & ایستا & گسسته & چندعاملی-رقابتی\\
خلبان خودکار & جزئی & اتفاقی & ترتیبی & پویا & پیوسته & چند‌عاملی\\
بازی فرار & جزئی & اتفاقی & ترتیبی & پویا & پیوسته & چندعاملی-همکاری\\
 \end{tabular} 

\end{document}